{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-12T10:03:26.987394Z",
     "start_time": "2026-01-12T10:03:26.903758Z"
    }
   },
   "source": "import numpy as np",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T11:58:45.129250Z",
     "start_time": "2026-01-12T11:58:45.120684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GNB:\n",
    "    def __init__(self):\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.classes = None\n",
    "        self.priors = {}\n",
    "    def fit(self,x,y):\n",
    "        self.classes = set(y)\n",
    "\n",
    "        for cls in self.classes:\n",
    "            x_cls = [x[i] for i in range(len(x)) if y[i] == cls]\n",
    "            self.priors[cls] = len(x_cls)/len(x)\n",
    "            self.mean[cls] = []\n",
    "            self.var[cls] = []\n",
    "            for i in range(x.shape[1]):\n",
    "                features_values = [val[i] for val in x_cls]\n",
    "                mean = sum(features_values)/len(features_values)\n",
    "                # variance formula is summation of (xi- mean) ** 2 / len(features)\n",
    "                # sum((x - mean) ** 2 for x in feature_values) / len(feature_values)\n",
    "                var = np.var(features_values) + 1e-9 # for avoid -inf. log(0) is -inf\n",
    "\n",
    "                self.mean[cls].append(mean)\n",
    "                self.var[cls].append(var)\n",
    "\n",
    "    def gaussian_log_pdf(self,x,mean,var):\n",
    "        # formula is -(0.5 * log(2 *pi * var)) - (((x - mean)**2)/(2*var))\n",
    "        return - 0.5*np.log(2 * np.pi * var) - ((x- mean) **2) /(2*var)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        for x in X:\n",
    "            class_prob = {}\n",
    "            for cls  in self.classes:\n",
    "                # Start with log prior\n",
    "                prior_prob = np.log(self.priors[cls])\n",
    "                # find the gaussian log pdf for each feature.\n",
    "                for i in range(len(x)):\n",
    "\n",
    "                    prior_prob += self.gaussian_log_pdf(x[i], mean=self.mean[cls][i],var=self.var[cls][i])\n",
    "                class_prob[cls] = prior_prob\n",
    "\n",
    "            predictions.append(max(class_prob,key=class_prob.get))\n",
    "        return predictions\n"
   ],
   "id": "194192529c5cf7c1",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T11:58:45.579450Z",
     "start_time": "2026-01-12T11:58:45.574637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training features (continuous values)\n",
    "X_train = np.array([\n",
    "    [1.0, 2.0],\n",
    "    [1.1, 1.8],\n",
    "    [0.9, 2.2],\n",
    "    [5.0, 8.0],\n",
    "    [6.0, 9.0],\n",
    "    [5.5, 8.5]\n",
    "])\n",
    "\n",
    "# Training labels\n",
    "y_train = np.array([\n",
    "    0, 0, 0,   # Class 0\n",
    "    1, 1, 1    # Class 1\n",
    "])\n",
    "\n",
    "X_test = np.array([\n",
    "    [1.0, 2.1],   # Close to class 0\n",
    "    [5.8, 8.7],   # Close to class 1\n",
    "    [3.0, 4.0]    # Somewhere in between\n",
    "])"
   ],
   "id": "b8c1e5dca0b8a17e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T11:58:46.009728Z",
     "start_time": "2026-01-12T11:58:46.003815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = GNB()\n",
    "model.fit(x=X_train,y=y_train)"
   ],
   "id": "38d06039953c83c7",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T11:59:18.044475Z",
     "start_time": "2026-01-12T11:59:18.042319Z"
    }
   },
   "cell_type": "code",
   "source": "predict = model.predict(X_test)",
   "id": "23e03297671238df",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T11:59:18.282719Z",
     "start_time": "2026-01-12T11:59:18.278667Z"
    }
   },
   "cell_type": "code",
   "source": "predict",
   "id": "b59b78866f1077fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0), np.int64(1), np.int64(1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class MultinomialNaiveBayes:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.feature_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_priors = {}\n",
    "        self.feature_probs = {}\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: List of feature count vectors\n",
    "        y: Labels\n",
    "        \"\"\"\n",
    "        n_samples = len(y)\n",
    "        n_features = len(X[0])\n",
    "        self.vocab_size = n_features\n",
    "\n",
    "        for x, cls in zip(X, y):\n",
    "            self.class_counts[cls] += 1\n",
    "            for i in range(n_features):\n",
    "                self.feature_counts[cls][i] += x[i]\n",
    "\n",
    "        for cls in self.class_counts:\n",
    "            self.class_priors[cls] = math.log(self.class_counts[cls] / n_samples)\n",
    "\n",
    "            total_count = sum(self.feature_counts[cls].values())\n",
    "            self.feature_probs[cls] = {}\n",
    "\n",
    "            for i in range(n_features):\n",
    "                # Laplace smoothing\n",
    "                prob = (self.feature_counts[cls][i] + self.alpha) / \\\n",
    "                       (total_count + self.alpha * self.vocab_size)\n",
    "                self.feature_probs[cls][i] = math.log(prob)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        for x in X:\n",
    "            scores = {}\n",
    "\n",
    "            for cls in self.class_priors:\n",
    "                score = self.class_priors[cls]\n",
    "                for i in range(len(x)):\n",
    "                    score += x[i] * self.feature_probs[cls][i]\n",
    "                scores[cls] = score\n",
    "\n",
    "            predictions.append(max(scores, key=scores.get))\n",
    "\n",
    "        return predictions\n"
   ],
   "id": "e80c65a3bee4fa16"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
